# CUDA GPU Setup f√ºr KRAI Engine

## üöÄ Voraussetzungen

### 1. NVIDIA Container Toolkit
```bash
# Ubuntu/Debian
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update && sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker
```

### 2. NVIDIA-Treiber (Windows/Linux)
- **Windows**: NVIDIA GeForce Experience oder NVIDIA Driver Downloads
- **Linux**: `nvidia-driver-535` oder neuer
- √úberpr√ºfen mit `nvidia-smi`

## üê≥ CUDA Deployment

### 1. GPU-f√§higen Container bauen
```bash
# CUDA-f√§higen KRAI Engine bauen
docker-compose -f docker-compose.cuda.yml build krai-engine

# Oder manuell
docker build -f Dockerfile.cuda -t krai-engine:cuda .
```

### 2. GPU-Container starten
```bash
# Vollst√§ndigen CUDA-Stack starten
docker-compose -f docker-compose.cuda.yml up -d

# Nur KRAI Engine mit GPU
docker-compose -f docker-compose.cuda.yml up -d krai-engine krai-ollama
```

### 3. GPU-Status √ºberpr√ºfen
```bash
# GPU-Status im Container pr√ºfen
docker exec krai-engine-cuda nvidia-smi

# PyTorch CUDA-Test
docker exec krai-engine-cuda python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else None}')"
```

## üìä Performance-Vorteile

### Ohne GPU (aktuell)
- **Tier**: Conservative
- **Models**: llama3.2:3b (CPU-only)
- **Performance**: Langsamer, CPU-beschr√§nkt
- **Memory**: 7.8 GB RAM genutzt

### Mit CUDA
- **Tier**: High Performance
- **Models**: llama3.2:3b, llava:7b (GPU-beschleunigt)
- **Performance**: 10-50x schneller f√ºr AI-Inference
- **Memory**: GPU RAM + 7.8 GB System-RAM

## üîß Konfiguration

### Umgebungsvariablen
```bash
# .env Datei erg√§nzen
GPU_ENABLED=true
CUDA_VISIBLE_DEVICES=0
TORCH_CUDA_ARCH_LIST="8.6;8.9;9.0"  # Passend zur GPU
```

### Model-Optimierung
```bash
# Gr√∂√üere Models mit GPU
docker exec krai-ollama-cuda ollama pull llama3.2:7b
docker exec krai-ollama-cuda ollama pull llava:7b
docker exec krai-ollama-cuda ollama pull nomic-embed-text:latest
```

## üêõ Fehlerbehebung

### 1. "No GPU detected"
```bash
# NVIDIA-Treiber pr√ºfen
nvidia-smi

# Docker GPU-Support pr√ºfen
docker run --rm --gpus all nvidia/cuda:12.1-base-ubuntu22.04 nvidia-smi
```

### 2. CUDA-Laufzeitfehler
```bash
# CUDA-Version pr√ºfen
docker exec krai-engine-cuda nvcc --version

# PyTorch CUDA-Installation pr√ºfen
docker exec krai-engine-cuda python -c "import torch; print(torch.version.cuda)"
```

### 3. Memory-Probleme
```bash
# GPU-Memory √ºberwachen
watch -n 1 nvidia-smi

# Container-Limits anpassen
docker-compose -f docker-compose.cuda.yml down
# docker-compose.cuda.yml editieren
docker-compose -f docker-compose.cuda.yml up -d
```

## üìà Monitoring

### GPU-Monitoring
```bash
# Live GPU-Status
docker exec krai-engine-cuda nvidia-smi -l 1

# GPU-Auslastung in Logs
docker logs krai-engine-cuda | grep -i gpu
```

### Performance-Test
```bash
# AI-Inference Benchmark
curl -X POST http://localhost:8000/health
# Antwortzeit sollte mit GPU deutlich schneller sein
```

## üîÑ Wechsel zwischen CPU/GPU

### Zu GPU wechseln
```bash
# Stoppen
docker-compose down

# GPU-Start
docker-compose -f docker-compose.cuda.yml up -d
```

### Zu CPU zur√ºckkehren
```bash
# Stoppen
docker-compose -f docker-compose.cuda.yml down

# CPU-Start
docker-compose up -d
```

## üéØ Empfohlene Models mit GPU

```bash
# Gro√üe Language Models
docker exec krai-ollama-cuda ollama pull llama3.2:7b
docker exec krai-ollama-cuda ollama pull llama3.2:13b

# Vision Models
docker exec krai-ollama-cuda ollama pull llava:7b
docker exec krai-ollama-cuda ollama pull llava:13b

# Embedding Models
docker exec krai-ollama-cuda ollama pull nomic-embed-text:latest
docker exec krai-ollama-cuda ollama pull mxbai-embed-large
```

## ‚ö° Erwartete Performance-Verbesserung

| Task | CPU-only | With GPU | Verbesserung |
|------|----------|----------|-------------|
| Text Generation | 10-30 sec | 0.5-2 sec | 15-60x |
| Image Analysis | 60-120 sec | 2-5 sec | 20-60x |
| Embeddings | 5-15 sec | 0.2-1 sec | 5-75x |
| Document Processing | 30-60 sec | 2-8 sec | 4-30x |

## üîí Sicherheitshinweise

- GPU-Container ben√∂tigen elevated privileges
- NVIDIA-Treiber m√ºssen aktuell sein
- GPU-Memory sollte √ºberwacht werden
- Nur vertrauensw√ºrdige Code auf GPU ausf√ºhren
