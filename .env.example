    # ===========================================
    # DATABASE ADAPTER CONFIGURATION
    # ===========================================
    # Database type: 'supabase', 'postgresql', or 'docker_postgresql'
    # Default: 'supabase' (Supabase Cloud)
    DATABASE_TYPE=supabase

    # ===========================================
    # SUPABASE CLOUD CONFIGURATION
    # ===========================================
    # Required for DATABASE_TYPE=supabase
    SUPABASE_URL=https://crujfdpqdjzcfqeyhang.supabase.co
    SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImNydWpmZHBxZGp6Y2ZxZXloYW5nIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTkwNDY1MTUsImV4cCI6MjA3NDYyMjUxNX0.kDSf9jMYbNgzV8v1f-_kSoSy_cAMFLG367m9ZbDsBkw
    SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImNydWpmZHBxZGp6Y2ZxZXloYW5nIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1OTA0NjUxNSwiZXhwIjoyMDc0NjIyNTE1fQ.5MnFW5MuKdS6ZNvKv5iTWH-jv_ZB1SgeoP7cVGI7cdE
    SUPABASE_STORAGE_URL=https://crujfdpqdjzcfqeyhang.supabase.co/storage/v1

    # ===========================================
    # POSTGRESQL CONFIGURATION
    # ===========================================
    # Required for DATABASE_TYPE=postgresql or DATABASE_TYPE=docker_postgresql
    # Also used by Supabase adapter for direct asyncpg connections (cross-schema queries)
    
    # Option 1: Connection URL (recommended)
    DATABASE_CONNECTION_URL=postgresql://postgres:YOUR_DB_PASSWORD@db.crujfdpqdjzcfqeyhang.supabase.co:5432/postgres
    POSTGRES_URL=postgresql://postgres:YOUR_DB_PASSWORD@localhost:5432/krai
    
    # Option 2: Individual connection parameters (alternative to URL)
    POSTGRES_HOST=localhost
    POSTGRES_PORT=5432
    POSTGRES_DB=krai
    POSTGRES_USER=postgres
    POSTGRES_PASSWORD=YOUR_DB_PASSWORD
    
    # Schema prefix for multi-tenant support (default: 'krai')
    # Creates schemas: krai_core, krai_content, krai_intelligence, krai_system
    DATABASE_SCHEMA_PREFIX=krai

    # ===========================================
    # R2 STORAGE CONFIGURATION (Cloudflare)
    # ===========================================
    R2_ACCESS_KEY_ID=9c59473961632448c91db3ef9dbd35ab
    R2_SECRET_ACCESS_KEY=9cc62a9506ac9ec6e8373a39fa86268bc187632e5548e8c37b1c6c9c071755e4
    R2_BUCKET_NAME_DOCUMENTS=krai-documents-images
    R2_BUCKET_NAME_ERROR=krai-error-images
    R2_BUCKET_NAME_PARTS=krai-parts-images
    R2_ENDPOINT_URL=https://a88f92c913c232559845adb9001a5d14.eu.r2.cloudflarestorage.com
    R2_REGION=auto

    # ===========================================
    # R2 PUBLIC URLS
    # ===========================================
    R2_PUBLIC_URL_DOCUMENTS=https://pub-68e63cf2d6ac4222adaab70dfbc29ec4.r2.dev
    R2_PUBLIC_URL_ERROR=https://pub-e327cb3371c741e08c5e8672e817d9cf.r2.dev
    R2_PUBLIC_URL_PARTS=https://pub-61c8b15e7bf24febbf8e0197ab237041.r2.dev

    # ===========================================
    # OLLAMA AI SERVICE CONFIGURATION
    # ===========================================
    OLLAMA_URL=http://localhost:11434
    OLLAMA_MODEL_EMBEDDING=nomic-embed-text:latest
    OLLAMA_MODEL_TEXT=llama3.2:latest
    
    # Vision Model - Auto-detected based on GPU VRAM
    # Override here if you want a specific model
    # bakllava:7b = 4GB VRAM (recommended - more stable than llava)
    # llava:7b = 4GB VRAM (alternative)
    # llava:latest = 11GB VRAM (for 12GB+ GPU)
    OLLAMA_MODEL_VISION=bakllava:7b
    
    # Disable vision processing if model keeps crashing
    # Set to 'true' to skip AI image analysis (faster, uses less VRAM)
    # The pipeline will still extract images but won't analyze them with AI
    DISABLE_VISION_PROCESSING=false
    
    # ===========================================
    # PRODUCT RESEARCH CONFIGURATION
    # ===========================================
    # Enable automatic online research for unknown products
    ENABLE_PRODUCT_RESEARCH=true
    
    # Tavily API for web search (optional, recommended)
    # Get free API key at: https://tavily.com
    # Without this, system will use direct manufacturer website URLs
    TAVILY_API_KEY=your_tavily_api_key_here
    
    # Research cache duration (days)
    RESEARCH_CACHE_DAYS=90
    
    # LLM Product Extraction - Maximum pages to scan
    # Default: 20 (scans first 20 pages for product info)
    # Set to 0 to scan ALL pages (slower but more thorough)
    # Set to 50 for medium coverage
    # Why limit? LLM is slow (~8s/page). 278 pages = 37 minutes!
    # Product specs are usually in first 20 pages anyway.
    LLM_MAX_PAGES=20
    
    # Maximum number of images to process with vision model per document
    # Lower values = more stable, higher values = more complete analysis
    # Recommended: 5-10 for 8GB VRAM, 10-20 for 12GB+ VRAM
    MAX_VISION_IMAGES=5

# ===========================================
# PROCESSING PIPELINE SETTINGS
# ===========================================
# Control which extraction steps are enabled
# Set to 'false' to skip specific extraction steps

# Extract product models (recommended: true)
ENABLE_PRODUCT_EXTRACTION=true

# Extract spare parts (recommended: true for service manuals)
ENABLE_PARTS_EXTRACTION=true

# Extract error codes (recommended: true for service manuals)
ENABLE_ERROR_CODE_EXTRACTION=true

# Extract document versions (recommended: true)
ENABLE_VERSION_EXTRACTION=true

# Extract images from PDFs (recommended: true)
ENABLE_IMAGE_EXTRACTION=true

# Run OCR on images (recommended: true)
ENABLE_OCR=true

# Run Vision AI on images (optional: false if low VRAM)
ENABLE_VISION_AI=true

# Extract links and videos (recommended: true)
ENABLE_LINK_EXTRACTION=true

# Generate embeddings for semantic search (recommended: true)
ENABLE_EMBEDDINGS=true

# ===========================================
# OBJECT STORAGE UPLOAD SETTINGS (R2)
# ===========================================
# Control what gets uploaded to R2 object storage
# Images are always saved to database, these settings control R2 upload

# Upload extracted images to R2 (recommended: true)
# Images will have public URLs for viewing
UPLOAD_IMAGES_TO_R2=false

# Upload original PDF documents to R2 (optional: false)
# PDFs stay local by default, only enable if you need cloud backup
UPLOAD_DOCUMENTS_TO_R2=false

# ===========================================
# LOGGING CONFIGURATION
# ===========================================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
# DEBUG: most verbose diagnostics (development recommended)
# INFO: balanced operational visibility (production default)
# WARNING: only potential issues and failures
# ERROR: failures requiring attention
# CRITICAL: only catastrophic issues
LOG_LEVEL=INFO

# Enable console logging
LOG_TO_CONSOLE=true

# Enable file logging
LOG_TO_FILE=true

# Log directory (default: backend/logs)
LOG_DIR=backend/logs

# Log rotation mode: size (file size) or time (time-based)
LOG_ROTATION=size

# Maximum log file size in bytes (for size-based rotation)
# Default: 10MB
LOG_MAX_BYTES=10000000

# Number of backup log files to keep
# Example rotation: processor_v2.log â†’ processor_v2.log.1, processor_v2.log.2 ...
# Files beyond the configured count are removed automatically
LOG_BACKUP_COUNT=5

# Time-based rotation settings (only used if LOG_ROTATION=time)
# When to rotate: midnight, W0-W6 (weekday), or H (hourly)
LOG_ROTATION_WHEN=midnight

# Rotation interval (e.g., 1 for daily with midnight)
LOG_ROTATION_INTERVAL=1

# ===========================================
# OCR FALLBACK CONFIGURATION
# ===========================================
# Enable OCR fallback for pages without extractable text
# Requires: pip install pytesseract pillow
# Also requires Tesseract binary: https://github.com/tesseract-ocr/tesseract
ENABLE_OCR_FALLBACK=false

# ===========================================
# EXTERNAL API KEYS
# ===========================================
# YouTube Data API v3
# Get your key at: https://console.cloud.google.com/apis/credentials
# Free quota: 10,000 units/day (1 video = 1 unit)
YOUTUBE_API_KEY=your_youtube_api_key_here