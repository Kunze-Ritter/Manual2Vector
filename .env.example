# ==========================================
# KRAI ENGINE ENVIRONMENT CONFIGURATION
# ==========================================
# Copy this file to `.env` and adjust values before running the stack.
# Use `./setup.sh` (Linux/macOS) or `setup.bat` (Windows) to generate secrets automatically.
# Keep this file version-controlled for reference, but never commit a populated `.env` file.
# Store production credentials in a secure secrets manager (1Password, Vault, etc.).
# ----------------------------------------------------------------------------
# Environment loading guidance:
# - Prefer maintaining a single `.env` at the repository root.
# - Legacy scripts that call `load_dotenv(".env.database")` should be updated to call `load_dotenv()` without arguments.
# - Until updated, you may create a local `.env.database` that mirrors the variables defined in your root `.env`.
# - Prefer using `scripts/_env.load_env()` in Python helpers and passing `extra_files=['.env.database']` only when a legacy override is required.
# ----------------------------------------------------------------------------
# Pro Tip: Comment out sections you do not use to avoid accidentally mixing configs.

# ==========================================
# APPLICATION SETTINGS
# ==========================================
# Runtime environment: production, staging, development
ENV=production

# Backend API host binding (0.0.0.0 for Docker, 127.0.0.1 for local only)
API_HOST=0.0.0.0

# Backend API port (FastAPI / Uvicorn)
API_PORT=8000

# Global log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=DEBUG


# ==========================================
# DATABASE CONFIGURATION
# ==========================================
# Choose PostgreSQL OR Supabase, not both at the same time.

# --- PostgreSQL (Docker/Local) ---
# Database backend type: postgresql or sqlite (PostgreSQL recommended)
DATABASE_TYPE=postgresql

# Hostname for local Docker Compose service
DATABASE_HOST=krai-postgres

# PostgreSQL service port
DATABASE_PORT=5432

# Database name for local deployment
DATABASE_NAME=krai

# PostgreSQL username used by the application
DATABASE_USER=krai_user

# PostgreSQL password (change for production!)
DATABASE_PASSWORD=krai_secure_password

# --- Supabase (Cloud) ---
# Supabase project URL (https://<project>.supabase.co)
SUPABASE_URL=https://your-project.supabase.co

# Supabase anonymous key (client-side usage)
SUPABASE_ANON_KEY=your-anon-key-here

# Supabase service role key (server-side only, keep secret!)
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key-here

# Supabase storage API base URL
SUPABASE_STORAGE_URL=https://your-project.supabase.co/storage/v1

# Optional password for direct Supabase PostgreSQL connections (deprecated scripts only)
#SUPABASE_DB_PASSWORD=your-supabase-db-password

# Direct PostgreSQL connection string (optional alternative to local DB)
DATABASE_CONNECTION_URL=postgresql://postgres:your-password@db.your-project.supabase.co:5432/postgres

# Optional (deprecated) legacy alias used by older scripts â€” prefer DATABASE_CONNECTION_URL
#DATABASE_URL=postgresql://krai_user:krai_secure_password@krai-postgres:5432/krai            # Local PostgreSQL example
#DATABASE_URL=postgresql://postgres:your-password@db.your-project.supabase.co:5432/postgres  # Supabase example


# ==========================================
# OBJECT STORAGE CONFIGURATION
# ==========================================
# Choose MinIO OR Cloudflare R2 depending on your deployment target.

# --- MinIO (Docker/Local) ---
# Object storage implementation (s3-compatible for both MinIO & R2)
OBJECT_STORAGE_TYPE=s3

# Internal endpoint for MinIO service in Docker
OBJECT_STORAGE_ENDPOINT=http://krai-minio:9000

# Optional (deprecated) legacy alias mirroring OBJECT_STORAGE_ENDPOINT
#MINIO_ENDPOINT=http://krai-minio:9000

# MinIO access key (change for production!)
OBJECT_STORAGE_ACCESS_KEY=minioadmin

# MinIO secret key (change for production!)
OBJECT_STORAGE_SECRET_KEY=minioadmin123

# AWS region style identifier (MinIO accepts any string)
OBJECT_STORAGE_REGION=us-east-1

# Set to true if MinIO endpoint uses HTTPS (self-hosted defaults to false)
OBJECT_STORAGE_USE_SSL=false

# Public URL used by the frontend to access stored files
OBJECT_STORAGE_PUBLIC_URL=http://localhost:9000

# --- Cloudflare R2 (Cloud) ---
# Cloudflare R2 access key ID
R2_ACCESS_KEY_ID=your-r2-access-key-id

# Cloudflare R2 secret access key
R2_SECRET_ACCESS_KEY=your-r2-secret-access-key

# Bucket name for processed documents (documents/manuals)
R2_BUCKET_NAME_DOCUMENTS=your-bucket-name

# R2 S3-compatible API endpoint URL
R2_ENDPOINT_URL=https://your-account-id.eu.r2.cloudflarestorage.com

# R2 selected region (use `auto` unless you have a specific requirement)
R2_REGION=auto

# Public CDN URL for shared documents bucket
R2_PUBLIC_URL_DOCUMENTS=https://pub-your-documents-bucket.r2.dev

# Public CDN URL for error screenshots or diagnostic assets
R2_PUBLIC_URL_ERROR=https://pub-your-error-bucket.r2.dev

# Public CDN URL for spare parts assets
R2_PUBLIC_URL_PARTS=https://pub-your-parts-bucket.r2.dev

# Upload extracted images to R2 (recommended true for cloud deployments)
UPLOAD_IMAGES_TO_R2=true

# Upload original source documents to R2 (enable for cloud backup)
UPLOAD_DOCUMENTS_TO_R2=false


# ==========================================
# AI SERVICE CONFIGURATION
# ==========================================
# Consolidated configuration for Ollama-based AI services and GPU controls.

# --- Ollama Base ---
# AI service provider type (ollama or openai). Currently supports `ollama`.
AI_SERVICE_TYPE=ollama

# Base URL for internal AI service abstraction (used by backend)
AI_SERVICE_URL=http://krai-ollama:11434

# Ollama server URL (used by backend - consistent naming)
# Note: Backend uses OLLAMA_URL, not OLLAMA_BASE_URL or AI_SERVICE_URL
OLLAMA_URL=http://krai-ollama:11434
# For host CLI/testing, you may override with http://localhost:11434

# --- Ollama Models ---
# Embedding model (vector generation for semantic search)
OLLAMA_MODEL_EMBEDDING=nomic-embed-text:latest

# Structured extraction model (product specs as JSON)
OLLAMA_MODEL_EXTRACTION=qwen2.5:3b

# Conversational model (agent/chat responses)
OLLAMA_MODEL_CHAT=llama3.2:3b

# Vision-capable model (diagram/OCR understanding)
OLLAMA_MODEL_VISION=llava:7b

# Legacy/fallback text model (deprecated path support)
OLLAMA_MODEL_TEXT=qwen2.5:3b

# Context window tokens for Ollama prompts (higher requires more VRAM)
OLLAMA_NUM_CTX=8192

# --- Vision Processing ---
# Disable AI-based vision analysis entirely (images still extracted locally)
DISABLE_VISION_PROCESSING=false

# Maximum number of images analyzed per document (tune for VRAM limits)
MAX_VISION_IMAGES=5

# --- Solution Translation ---
# Enable automatic translation of troubleshooting steps via LLM
ENABLE_SOLUTION_TRANSLATION=false

# Target language for solution translation (ISO code, e.g. de, en, fr)
SOLUTION_TRANSLATION_LANGUAGE=de

# --- LLM Extraction Controls ---
# Maximum document pages scanned by LLM extraction (0 = all pages, -1 = disabled)
LLM_MAX_PAGES=50

# --- GPU Configuration ---
# Enable GPU acceleration for OpenCV/ML pipelines (requires CUDA drivers)
USE_GPU=false

# CUDA device index to target (0 = primary GPU)
CUDA_VISIBLE_DEVICES=0

# --- Visual Embeddings ---
# Vision embedding model identifier (used for multimodal search indexing)
AI_VISUAL_EMBEDDING_MODEL=vidore/colqwen2.5-v0.2


# ==========================================
# AUTHENTICATION & SECURITY
# ==========================================
# Generate fresh RSA keys for production and keep them secret!

# --- JWT Configuration ---
# JWT signing algorithm (RS256 recommended for asymmetric keys)
JWT_ALGORITHM=RS256

# Access token lifetime in minutes
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=60

# Refresh token lifetime in days
JWT_REFRESH_TOKEN_EXPIRE_DAYS=30

# Base64-encoded PKCS8 private key (DER format)
JWT_PRIVATE_KEY=

# Base64-encoded SubjectPublicKeyInfo public key (DER format)
JWT_PUBLIC_KEY=

# PowerShell key generation:
#   $key = [System.Security.Cryptography.RSA]::Create(2048)
#   [Convert]::ToBase64String($key.ExportPkcs8PrivateKey())
#   [Convert]::ToBase64String($key.ExportSubjectPublicKeyInfo())
# OpenSSL alternative (DER):
#   openssl genpkey -algorithm RSA -pkeyopt rsa_keygen_bits:2048 -out jwt_private.pem
#   openssl pkcs8 -topk8 -inform PEM -outform DER -nocrypt -in jwt_private.pem -out jwt_private.der
#   openssl rsa -in jwt_private.pem -pubout -outform DER -out jwt_public.der
#   base64 -w0 jwt_private.der
#   base64 -w0 jwt_public.der

# --- Security Controls ---
# Maximum failed login attempts before account lockout
MAX_LOGIN_ATTEMPTS=5

# Account lockout duration in minutes
ACCOUNT_LOCKOUT_DURATION_MINUTES=15

# Password complexity requirements (enable as needed; validation honors these flags)
PASSWORD_REQUIRE_UPPERCASE=false
PASSWORD_REQUIRE_LOWERCASE=false
PASSWORD_REQUIRE_NUMBER=false
PASSWORD_REQUIRE_SPECIAL=false

# Minimum password length enforced by backend validation (default 12 if unset)
PASSWORD_MIN_LENGTH=12

# --- Session Management ---
# Session idle timeout in minutes
SESSION_TIMEOUT_MINUTES=60

# Remember-me token lifetime in days
REMEMBER_ME_DAYS=30

# --- Default Admin Bootstrap ---
# Default admin email created on first startup (override before production!)
DEFAULT_ADMIN_EMAIL=admin@example.com

# Default admin username
DEFAULT_ADMIN_USERNAME=admin

# Default admin first name
DEFAULT_ADMIN_FIRST_NAME=System

# Default admin last name
DEFAULT_ADMIN_LAST_NAME=Administrator

# Default admin password (leave blank to prompt during setup)
DEFAULT_ADMIN_PASSWORD=


# ==========================================
# PROCESSING PIPELINE SETTINGS
# ==========================================
# Toggle specific extraction steps for debugging or resource management.

# Extract product models from manuals (recommended: true)
ENABLE_PRODUCT_EXTRACTION=true

# Extract spare parts catalogs (recommended for service manuals)
ENABLE_PARTS_EXTRACTION=true

# Extract diagnostic error codes (recommended: true)
ENABLE_ERROR_CODE_EXTRACTION=true

# Extract document version metadata (recommended: true)
ENABLE_VERSION_EXTRACTION=true

# Extract inline images from PDFs (recommended: true)
ENABLE_IMAGE_EXTRACTION=true

# Run OCR on extracted images for searchable text (depends on Tesseract/OpenCV)
ENABLE_OCR=true

# Run AI-based vision analysis on extracted images (set false if low VRAM)
ENABLE_VISION_AI=true

# Extract outbound links and embedded videos for enrichment
ENABLE_LINK_EXTRACTION=true

# Generate embeddings for semantic search (required for vector search)
ENABLE_EMBEDDINGS=true


# ==========================================
# WEB SCRAPING CONFIGURATION
# ==========================================
# Controls the scraping backend (BeautifulSoup, Firecrawl) and related services.

# --- Scraping Backend Selection ---
# Available options: beautifulsoup (local HTML parsing), firecrawl (cloud service)
SCRAPING_BACKEND=beautifulsoup

# Enable post-processing link enrichment to fetch additional metadata
ENABLE_LINK_ENRICHMENT=true

# Enable manufacturer crawling workflows (Firecrawl recommended)
ENABLE_MANUFACTURER_CRAWLING=false

# --- Firecrawl Configuration (Only if SCRAPING_BACKEND=firecrawl) ---
# Firecrawl API base URL (self-hosted or cloud endpoint)
FIRECRAWL_API_URL=http://krai-firecrawl-api:3002

# LLM provider name used by Firecrawl (openai, ollama, etc.)
FIRECRAWL_LLM_PROVIDER=ollama

# Default LLM model for summarization/extraction via Firecrawl
FIRECRAWL_MODEL_NAME=qwen2.5:3b

# Embedding model for Firecrawl vector outputs
FIRECRAWL_EMBEDDING_MODEL=nomic-embed-text:latest

# Maximum concurrent Firecrawl jobs allowed
FIRECRAWL_MAX_CONCURRENCY=3

# Block heavy media downloads during scraping (true/false)
FIRECRAWL_BLOCK_MEDIA=true

# Allow callbacks to local webhook endpoints (set false for production)
FIRECRAWL_ALLOW_LOCAL_WEBHOOKS=true

# Optional proxy configuration (leave blank if unused)
FIRECRAWL_PROXY_SERVER=
FIRECRAWL_PROXY_USERNAME=
FIRECRAWL_PROXY_PASSWORD=

# Maximum scrape duration per request in seconds
FIRECRAWL_SCRAPE_TIMEOUT=120

# Maximum crawl duration for multi-page jobs in seconds
FIRECRAWL_CRAWL_TIMEOUT=600

# Retry attempts for failed Firecrawl jobs
FIRECRAWL_RETRIES=2

# Optional OpenAI API key (required if FIRECRAWL_LLM_PROVIDER=openai)
OPENAI_API_KEY=


# ==========================================
# EXTERNAL API KEYS & TUNNELS
# ==========================================
# Keep all third-party credentials secret. Rotate keys regularly.

# --- YouTube Data API ---
# Obtain from https://console.cloud.google.com/apis/credentials (10k daily quota)
YOUTUBE_API_KEY=your-youtube-api-key-here

# --- Cloudflare Tunnels (Optional) ---
# Tunnel token for exposing n8n or automation webhook endpoints
CLOUDFLARE_TUNNEL_TOKEN=your-tunnel-token-here

# Public hostname for n8n automation platform
N8N_HOST=workflow.your-domain.com

# Public webhook URL for n8n workflows
WEBHOOK_URL=https://workflow.your-domain.com/

# Tunnel token for exposing Ollama securely over the internet
CLOUDFLARE_TUNNEL_TOKEN_OLLAMA=your-ollama-tunnel-token-here

# Public hostname for remote Ollama access (Cloudflare Tunnel)
# This is different from OLLAMA_URL (internal Docker network)
OLLAMA_BASE_URL=https://llm.your-domain.com


# ==========================================
# DOCKER COMPOSE CONFIGURATION
# ==========================================
# Variables specific to Docker Compose deployments

# --- n8n Configuration ---
# n8n basic auth username
N8N_BASIC_AUTH_USER=admin

# n8n basic auth password (change for production!)
N8N_BASIC_AUTH_PASSWORD=changeme

# n8n separate database password (different from main KRAI DB)
N8N_DATABASE_PASSWORD=krai_n8n_db_2024

# --- pgAdmin Configuration ---
# pgAdmin default admin email
PGADMIN_DEFAULT_EMAIL=admin@krai.local

# pgAdmin default admin password (change for production!)
PGADMIN_DEFAULT_PASSWORD=changeme

# --- MinIO Browser Configuration ---
# MinIO browser redirect URL (for console access)
MINIO_BROWSER_REDIRECT_URL=http://localhost:9001

# --- Firecrawl Bull Queue ---
# Firecrawl Bull queue authentication key (change for production!)
FIRECRAWL_BULL_AUTH_KEY=changeme_firecrawl_admin

# --- Playwright Configuration ---
# Playwright workspace auto-cleanup (true/false)
PLAYWRIGHT_WORKSPACE_DELETE_EXPIRED=true

# Playwright workspace expiry in days
PLAYWRIGHT_WORKSPACE_EXPIRY_DAYS=1

# --- Grafana Configuration (Enterprise) ---
# Grafana allow user sign-up (true/false)
GRAFANA_ALLOW_SIGN_UP=false

# --- Redis Configuration ---
# Redis URL for application cache (optional)
REDIS_URL=redis://krai-redis:6379

# --- Test Environment Variables ---
# Test database name (separate from production)
TEST_DATABASE_NAME=krai_test

# Test database user
TEST_DATABASE_USER=krai_test

# Test database password
TEST_DATABASE_PASSWORD=krai_test_password

# Test database connection URL
TEST_DATABASE_URL=postgresql://krai_test:krai_test_password@postgresql-test:5432/krai_test

# Test storage access key
TEST_STORAGE_ACCESS_KEY=test_access_key

# Test storage secret key
TEST_STORAGE_SECRET_KEY=test_secret_key

# Test storage endpoint
TEST_STORAGE_ENDPOINT=minio-test:9000

# Test Firecrawl Bull auth key
TEST_FIRECRAWL_BULL_AUTH_KEY=test_firecrawl_admin



# ==========================================
# SECURITY REMINDERS & DOCUMENTATION
# ==========================================
# - NEVER commit your populated `.env` file to version control.
# - Rotate secrets immediately if they leak or when personnel changes.
# - Store production secrets in a secure, access-controlled vault.
# - Review `docs/DOCKER_SETUP.md` for full deployment instructions.
# - Use `./setup.sh` or `setup.bat` to bootstrap local development safely.
