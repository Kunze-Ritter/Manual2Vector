# KRAI Technician Agent V2.1 - Architecture Guide

---

## âš ï¸ **DEPRECATION NOTICE - SUPABASE REFERENCES**

**This document contains historical Supabase references that are NO LONGER VALID.**

**Current Architecture (as of November 2024):**
- âœ… **PostgreSQL-only** (direct asyncpg connection pools)
- âŒ **Supabase** (deprecated and removed)
- âŒ **PostgREST** (deprecated and removed)

**For current setup instructions, see:**
- `docs/SUPABASE_TO_POSTGRESQL_MIGRATION.md` - Migration guide
- `DOCKER_SETUP.md` - Current PostgreSQL setup
- `DATABASE_SCHEMA.md` - Current schema reference

**This document is preserved for historical reference only.**

---

## ğŸ¯ **Correct Multi-Agent Architecture**

### **Key Discovery: Agent Tools ARE Sub-Agents!**

In n8n, `@n8n/n8n-nodes-langchain.agentTool` nodes have **built-in agent functionality**. You don't need separate Agent nodes for sub-agents!

## ğŸ“ **Architecture Overview**

```
User Question
    â†“
Main Coordinator Agent
â”œâ”€ Main LLM (llama3.2:latest)
â”œâ”€ Postgres Chat Memory
â””â”€ 4 Specialized Agent Tools:
    â”‚
    â”œâ”€ error_code_specialist (Agent Tool)
    â”‚   â”œâ”€ Error Code LLM (llama3.1:8b)
    â”‚   â”œâ”€ Specialized Prompt
    â”‚   â””â”€ Search Error Codes (HTTP Tool)
    â”‚
    â”œâ”€ parts_specialist (Agent Tool)
    â”‚   â”œâ”€ Parts LLM (llama3.2:latest)
    â”‚   â”œâ”€ Specialized Prompt
    â”‚   â””â”€ Search Parts (HTTP Tool)
    â”‚
    â”œâ”€ video_specialist (Agent Tool)
    â”‚   â”œâ”€ Video LLM (llama3.1:8b)
    â”‚   â”œâ”€ Specialized Prompt
    â”‚   â””â”€ Search Videos (HTTP Tool)
    â”‚
    â””â”€ manual_specialist (Agent Tool)
        â”œâ”€ Manual LLM (llama3.2:latest)
        â”œâ”€ Specialized Prompt
        â””â”€ Answer questions with vector store (Tool)
            â”œâ”€ Search Manuals Vector Store (PostgreSQL)
            â”œâ”€ Embeddings (embeddinggemma:latest)
            â””â”€ Ollama Chat Model (for vector store queries)
```

## ğŸ”§ **Component Breakdown**

### **1. Main Coordinator Agent**

**Type:** `@n8n/n8n-nodes-langchain.agent`

**Role:** Orchestrates specialists and synthesizes responses

**Prompt Strategy:**
- Extract information (manufacturer, model, error code)
- Decide which specialists to call
- Synthesize responses into coherent answer

**Key Responsibilities:**
- Context management (remembers conversation)
- Tool selection (calls right specialists)
- Response synthesis (combines specialist outputs)

---

### **2. Agent Tools (Specialists)**

Each Agent Tool is a **complete sub-agent** with:
1. **Name** â†’ Tool identifier for Main Agent
2. **Description** â†’ When to use this specialist
3. **Input Schema** â†’ Expected parameters (JSON)
4. **System Message** â†’ Specialized prompt
5. **LLM** â†’ Own reasoning capability
6. **Tool** â†’ Data access (HTTP or Vector Store)

---

#### **2.1 error_code_specialist**

**Type:** `@n8n/n8n-nodes-langchain.agentTool`

**When to call:**
- User mentions error code (e.g., "88.10", "C-9402")

**Input:**
```json
{
  "error_code": "88.10",
  "manufacturer": "Lexmark",
  "model": "CX963"
}
```

**Specialized Prompt:**
```
You are an Error Code Diagnosis Specialist.

Task: Diagnose error codes precisely using search_database tool.

Output Format (German):
**Fehlercode:** [code]
**Beschreibung:** [what it means]
**Ursache:** [root cause]
**Betroffene Komponenten:** [affected parts]
**LÃ¶sung:** [solution steps]
**Quelle:** [document, page]

Rules:
âœ… ALWAYS use the tool
âœ… Be precise and technical
âœ… Cite sources
âŒ NEVER make up information
```

**LLM:** llama3.1:8b (temp: 0.1)

**Tool:** HTTP Request â†’ `POST /api/v1/error-codes/search`

---

#### **2.2 parts_specialist**

**Type:** `@n8n/n8n-nodes-langchain.agentTool`

**When to call:**
- User asks about parts, replacements, part numbers

**Input:**
```json
{
  "search_term": "Fuser Unit",
  "manufacturer": "Lexmark",
  "model": "CX963"
}
```

**Specialized Prompt:**
```
You are a Spare Parts Specialist.

Task: Find exact part numbers using search_database tool.

Output Format (German):
**Ersatzteil:** [part name]
**Teilenummer:** [part number]
**Beschreibung:** [what it does]
**Kompatible Modelle:** [compatible devices]
**Quelle:** [catalog, page]

Rules:
âœ… ALWAYS use the tool
âœ… Provide exact part numbers
âœ… List compatible models
âŒ NEVER make up part numbers
```

**LLM:** llama3.2:latest (temp: 0.1)

**Tool:** HTTP Request â†’ `POST /api/v1/parts/search`

---

#### **2.3 video_specialist**

**Type:** `@n8n/n8n-nodes-langchain.agentTool`

**When to call:**
- User needs visual guidance or asks for videos

**Input:**
```json
{
  "search_term": "Fuser Unit replacement",
  "manufacturer": "Lexmark",
  "model": "CX963"
}
```

**Specialized Prompt:**
```
You are a Video Tutorial Specialist.

Task: Find relevant repair videos using search_database tool.

Output Format (German):
**Video:** [title]
**Link:** [URL]
**Beschreibung:** [what the video shows]
**Dauer:** [length]

Rules:
âœ… ALWAYS use the tool
âœ… Provide working video links
âœ… Describe what the video shows
âŒ NEVER make up video links
```

**LLM:** llama3.1:8b (temp: 0.1)

**Tool:** HTTP Request â†’ `POST /api/v1/videos/search`

---

#### **2.4 manual_specialist**

**Type:** `@n8n/n8n-nodes-langchain.agentTool`

**When to call:**
- User asks "how to" questions
- Needs step-by-step instructions

**Input:**
```json
{
  "query": "How to replace fuser unit",
  "manufacturer": "Lexmark",
  "model": "CX963"
}
```

**Specialized Prompt:**
```
You are a Service Manual Specialist.

Task: Provide step-by-step procedures using search_manuals tool.

Output Format (German):
**Anleitung:** [procedure name]

**Schritte:**
1. [Step 1]
2. [Step 2]
3. [Step 3]

**Hinweise:** [important notes, warnings]
**Werkzeug:** [required tools]
**Quelle:** [manual, page]

Rules:
âœ… ALWAYS use the tool
âœ… Provide clear step-by-step instructions
âœ… Include safety warnings
âŒ NEVER make up procedures
```

**LLM:** llama3.2:latest (temp: 0.1)

**Tool:** Answer questions with vector store
- Vector Store: PostgreSQL (`krai_intelligence.chunks`)
- Embeddings: embeddinggemma:latest
- Query LLM: Ollama Chat Model

---

## ğŸ”„ **Execution Flow**

### **Example: "Lexmark CX963 Fehlercode 88.10"**

```
1. User sends message
   â†“
2. Main Coordinator Agent receives input
   - Extracts: manufacturer=Lexmark, model=CX963, error_code=88.10
   - Decides: Call error_code_specialist
   â†“
3. error_code_specialist (Agent Tool)
   - Receives: { error_code: "88.10", manufacturer: "Lexmark", model: "CX963" }
   - Error Code LLM reasons: "I need to search the database"
   - Calls: Search Error Codes (HTTP Tool)
   â†“
4. Search Error Codes (HTTP Request)
   - POST http://backend:8000/api/v1/error-codes/search
   - Body: { "code": "88.10", "manufacturer": "Lexmark", "model": "CX963" }
   - Returns: Error code data
   â†“
5. error_code_specialist formats response
   - Uses specialized prompt
   - Formats in German
   - Returns to Main Agent
   â†“
6. Main Agent decides: "I need parts info"
   - Calls parts_specialist
   â†“
7. parts_specialist (Agent Tool)
   - Receives: { search_term: "Fuser Unit", manufacturer: "Lexmark", model: "CX963" }
   - Parts LLM reasons: "I need to search parts database"
   - Calls: Search Parts (HTTP Tool)
   â†“
8. Search Parts returns part numbers
   â†“
9. Main Agent decides: "I need repair instructions"
   - Calls manual_specialist
   â†“
10. manual_specialist (Agent Tool)
    - Receives: { query: "Fuser Unit replacement CX963" }
    - Manual LLM reasons: "I need to search manuals"
    - Calls: Answer questions with vector store
    â†“
11. Vector Store Tool
    - Embeddings Ollama creates query embedding
    - Search Manuals Vector Store searches Supabase
    - Returns relevant chunks
    - Ollama Chat Model formats response
    â†“
12. manual_specialist formats procedure
    â†“
13. Main Agent decides: "I need a video"
    - Calls video_specialist
    â†“
14. video_specialist returns video link
    â†“
15. Main Agent synthesizes final response:

ğŸ”´ **Fehlercode 88.10 - Fuser Unit defekt**

**Ursache:** [From error_code_specialist]

**LÃ¶sung:**
[From manual_specialist]

**BenÃ¶tigte Teile:**
[From parts_specialist]

ğŸ¥ **Video:**
[From video_specialist]
```

---

## âœ… **Why This Architecture Works**

### **1. Agent Tools = Sub-Agents**
- No need for separate Agent nodes
- Each Agent Tool has own LLM + Prompt + Tool
- Built-in agent reasoning

### **2. Specialized Prompts**
- Each specialist is expert in ONE domain
- Clear task definition
- Consistent output format

### **3. Independent LLMs**
- Each specialist has own reasoning
- No prompt conflicts
- Better quality responses

### **4. Simple Connections**
```
Main Agent â† Agent Tools (4 specialists)
Each Agent Tool â† LLM + Tool
```

### **5. Easy to Maintain**
- One workflow file
- Clear structure
- Easy to debug

---

## ğŸ§ª **Testing Scenarios**

### **Test 1: Error Code**
```
Input: "Lexmark CX963 Fehlercode 88.10"

Expected Flow:
1. Main Agent calls error_code_specialist
2. error_code_specialist calls HTTP API
3. Main Agent calls parts_specialist
4. Main Agent calls manual_specialist
5. Main Agent calls video_specialist
6. Main Agent synthesizes complete response

Expected Output:
âœ… Error diagnosis
âœ… Part numbers
âœ… Step-by-step procedure
âœ… Video link
âœ… All in German
âœ… Sources cited
```

### **Test 2: Parts Question**
```
Input: "Welche Fuser Unit passt zum CX963?"

Expected Flow:
1. Main Agent calls parts_specialist
2. parts_specialist calls HTTP API
3. Main Agent calls manual_specialist (installation)
4. Main Agent synthesizes response

Expected Output:
âœ… Part number
âœ… Compatible models
âœ… Installation instructions
```

### **Test 3: How-To Question**
```
Input: "Wie tausche ich die Trommel beim bizhub C750i?"

Expected Flow:
1. Main Agent calls manual_specialist
2. manual_specialist calls Vector Store
3. Main Agent calls video_specialist
4. Main Agent synthesizes response

Expected Output:
âœ… Step-by-step procedure
âœ… Safety warnings
âœ… Required tools
âœ… Video link
```

### **Test 4: Context Awareness**
```
Conversation:
User: "Ich habe einen Lexmark CX963"
Agent: [Acknowledges]
User: "Fehlercode 88.10"
Agent: [Full diagnosis]
User: "Welche Teile brauche ich?"

Expected:
âœ… Main Agent remembers context (Lexmark CX963)
âœ… Calls parts_specialist with context
âœ… No need to repeat device info
```

---

## ğŸ”§ **Configuration Details**

### **Main Agent Settings**
- **Model:** llama3.2:latest
- **Temperature:** 0.1 (deterministic)
- **Memory:** Postgres Chat Memory
- **Context Window:** 10 messages

### **Specialist LLM Settings**
- **error_code_specialist:** llama3.1:8b, temp 0.1
- **parts_specialist:** llama3.2:latest, temp 0.1
- **video_specialist:** llama3.1:8b, temp 0.1
- **manual_specialist:** llama3.2:latest, temp 0.1

### **Vector Store Settings**
- **Table:** krai_intelligence.chunks
- **Function:** match_chunks (PostgreSQL function)
- **Embeddings:** embeddinggemma:latest
- **Top K:** 5 (default)

### **HTTP Tools**
- **Timeout:** 30s (default)
- **Method:** POST
- **Content-Type:** application/json

---

## ğŸ› **Debugging Guide**

### **Check Specialist Calls**
```
n8n Execution Log:
1. Main Agent: "Calling error_code_specialist with params..."
2. error_code_specialist: "Using search_database tool..."
3. HTTP Request: "POST /api/v1/error-codes/search"
4. error_code_specialist: "Formatting response..."
5. Main Agent: "Received from error_code_specialist"
```

### **Common Issues**

**Specialist not called?**
- Check Main Agent prompt
- Check specialist description
- Verify specialist is connected to Main Agent

**Wrong specialist called?**
- Improve specialist descriptions
- Add more examples to Main Agent prompt
- Check input schema

**Empty responses?**
- Check backend API is running
- Check database has data
- Verify tool configurations
- Check LLM connections

**Tool not used by specialist?**
- Check specialist system message
- Verify tool is connected to specialist
- Check tool configuration

---

## ğŸ“Š **Performance Metrics**

### **Response Times**
- Simple query (1 specialist): ~2-3 seconds
- Complex query (4 specialists): ~8-10 seconds
- Context follow-up: ~1-2 seconds

### **Token Usage**
- Main Agent: ~500-1000 tokens/query
- Each Specialist: ~200-500 tokens/call
- Total: ~1500-3000 tokens/complex query

---

## ğŸš€ **Deployment**

### **Prerequisites**
```bash
# Ollama models
ollama pull llama3.2:latest
ollama pull llama3.1:8b
ollama pull embeddinggemma:latest

# Database
# Run migration 78 (vector search function)
psql -f database/migrations/78_vector_search_function.sql

# Backend API
# Ensure endpoints are running:
# - POST /api/v1/error-codes/search
# - POST /api/v1/parts/search
# - POST /api/v1/videos/search
```

### **Import Workflow**
```
1. n8n â†’ Import from File
2. Select: Technician-Agent V2.1.json
3. Configure credentials:
   - Ollama API
   - PostgreSQL (for memory and vector store)
     Host: localhost, Port: 5432, Database: krai
4. Activate workflow
5. Test with: "Lexmark CX963 Fehlercode 88.10"
```

---

## ğŸ“ˆ **Future Enhancements**

### **V2.2 Ideas**
- [ ] Add caching for specialist responses
- [ ] Add confidence scores
- [ ] Add fallback strategies
- [ ] Add multi-language support
- [ ] Add image analysis specialist
- [ ] Add diagnostic flowchart specialist
- [ ] Add performance monitoring

---

## ğŸ¯ **Summary**

**V2.1 Architecture:**
- âœ… Agent Tools ARE sub-agents (no separate nodes needed)
- âœ… Each specialist has own LLM + Prompt + Tool
- âœ… Specialized prompts for better quality
- âœ… Independent reasoning per domain
- âœ… Simple, maintainable structure
- âœ… Easy to debug
- âœ… Production-ready

**Key Learnings:**
- `@n8n/n8n-nodes-langchain.agentTool` has built-in agent functionality
- No need for complex sub-workflow architectures
- Specialized prompts > Generic prompts
- Independent LLMs > Shared LLM

**Ready for production!** ğŸš€
