# KRAI Quick Start Guide - Phases 1-6
# =====================================

Get KRAI up and running in 5 minutes with this streamlined setup guide. This guide covers the local-first architecture with Docker Compose, MinIO storage, and PostgreSQL database.

## ðŸš€ 5-Minute Setup

### Prerequisites

- **Docker & Docker Compose** (installed and running)
- **Git** (for cloning the repository)
- **8GB+ RAM** (recommended for optimal performance)
- **10GB+ free disk space**

### Step 1: Clone and Setup

```bash
# Clone the repository
git clone https://github.com/your-org/KRAI-minimal.git
cd KRAI-minimal

# Copy environment configuration
cp .env.example .env

# Quick configuration script
python scripts/quick_setup.py
```

### Step 2: Start Services

```bash
# Start all services with Docker Compose
docker-compose up -d

# Wait for services to be ready (automated)
python scripts/wait_for_services.py
```

### Step 3: Initialize Database

```bash
# Apply database migrations
python scripts/apply_migrations.py

# Verify setup
python scripts/health_check.py
```

### Step 3a: Optional - Setup Firecrawl (Advanced Web Scraping)

Firecrawl provides advanced web scraping with JavaScript rendering and LLM-based structured extraction. This is optional but recommended for production use.

**Prerequisites:**
- Additional 2GB RAM for Firecrawl services
- Docker Compose already running

**Quick Setup:**

```bash
# Start Firecrawl services
docker-compose up -d krai-redis krai-playwright krai-firecrawl-api krai-firecrawl-worker

# Wait for services to be ready
sleep 10

# Verify Firecrawl is running
curl http://localhost:3002/health

# Expected response: {"status":"healthy"}
```

**Enable Firecrawl in Configuration:**

Edit `.env` file:

```bash
# Change scraping backend from beautifulsoup to firecrawl
SCRAPING_BACKEND=firecrawl

# Optional: Enable advanced features
ENABLE_LINK_ENRICHMENT=true
ENABLE_MANUFACTURER_CRAWLING=true
```

**What You Get:**
- âœ… JavaScript rendering for dynamic websites
- âœ… LLM-ready Markdown output (better for AI analysis)
- âœ… Structured data extraction (product specs, error codes)
- âœ… Automatic fallback to BeautifulSoup if Firecrawl unavailable

**Access Points:**

- **Firecrawl API**: <http://localhost:3002>
- **Firecrawl Admin UI**: <http://localhost:3002/admin/@/queues> (password: changeme_firecrawl_admin)

**Skip This Step If:**
- You're just testing KRAI
- You don't need advanced web scraping
- You have limited RAM (< 16GB)

The system works perfectly with BeautifulSoup (default) for basic HTML scraping.

**Learn More:**
- Full documentation: `docs/PRODUCT_RESEARCH.md`
- Example scripts: `examples/firecrawl_*.py`
- Firecrawl vs BeautifulSoup comparison: See Product Research docs

### Step 4: Test the System

```bash
# Run quick validation test
python scripts/quick_test.py

# Test document processing
python scripts/test_single_document.py service_documents/sample.pdf
```

### Step 5: Access the System

- **API Documentation**: http://localhost:8000/docs
- **Dashboard**: http://localhost:3000
- **MinIO Console**: http://localhost:9001 (admin/password123)
- **Database**: localhost:5432 (krai_user/krai_password)

ðŸŽ‰ **KRAI is now running!** You can start processing documents and using the search functionality.

## ðŸ“‹ What You Get

This setup includes:

### Core Services
- **PostgreSQL Database** with all Phase 1-6 schemas
- **MinIO Object Storage** for documents and media
- **Ollama AI Service** for embeddings and LLM
- **FastAPI Backend** with REST API
- **React Frontend** for document management
- **Firecrawl Services** (optional) for advanced web scraping

### Phase 1-6 Features
- **Multimodal Processing**: Text, images, tables, videos, links
- **Hierarchical Chunking**: Smart document structure analysis
- **SVG Extraction**: Vector graphics processing and conversion
- **Context Extraction**: AI-powered media context analysis
- **Embedding Generation**: Cross-modal semantic embeddings
- **Advanced Search**: Unified multimodal search capabilities

### Development Tools
- **Automatic Migrations**: Database schema management
- **Health Monitoring**: Service status and metrics
- **Test Suites**: Comprehensive validation tests
- **Documentation**: API docs and user guides

## ðŸ”§ Configuration Options

### Basic Configuration

Edit `.env` file for basic customization:

```bash
# Database Configuration
POSTGRES_DB=krai_db
POSTGRES_USER=krai_user
POSTGRES_PASSWORD=your_secure_password

# Storage Configuration  
MINIO_ACCESS_KEY=your_access_key
MINIO_SECRET_KEY=your_secret_key

# AI Service Configuration
OPENAI_API_KEY=your_openai_key  # Optional - uses Ollama by default
OLLAMA_MODEL=llama2  # Local AI model
```

### Feature Flags

Enable/disable specific features:

```bash
# Core Features
ENABLE_HIERARCHICAL_CHUNKING=true
ENABLE_SVG_EXTRACTION=true
ENABLE_TABLE_EXTRACTION=true
ENABLE_CONTEXT_EXTRACTION=true
ENABLE_MULTIMODAL_SEARCH=true

# Advanced Features
ENABLE_TWO_STAGE_SEARCH=true
ENABLE_CONTEXT_AWARE_IMAGES=true
ENABLE_ERROR_CODE_DETECTION=true

# Web Scraping Features (Optional - requires Firecrawl)
SCRAPING_BACKEND=firecrawl  # or 'beautifulsoup'
ENABLE_LINK_ENRICHMENT=false
ENABLE_MANUFACTURER_CRAWLING=false
```

### Performance Tuning

Optimize for your hardware:

```bash
# For High-Performance Systems
EMBEDDING_BATCH_SIZE=50
MAX_CONCURRENT_PROCESSES=8
DATABASE_POOL_SIZE=20

# For Resource-Constrained Systems
EMBEDDING_BATCH_SIZE=10
MAX_CONCURRENT_PROCESSES=2
DATABASE_POOL_SIZE=5
```

## ðŸ“ Directory Structure

```
KRAI-minimal/
â”œâ”€â”€ backend/                 # Python backend services
â”‚   â”œâ”€â”€ api/                # REST API endpoints
â”‚   â”œâ”€â”€ services/           # Core business logic
â”‚   â”œâ”€â”€ pipeline/           # Document processing pipeline
â”‚   â””â”€â”€ models/             # Data models and schemas
â”œâ”€â”€ frontend/               # React web application
â”‚   â”œâ”€â”€ src/                # React components
â”‚   â”œâ”€â”€ public/             # Static assets
â”‚   â””â”€â”€ package.json        # Node.js dependencies
â”œâ”€â”€ database/               # Database schemas and migrations
â”‚   â”œâ”€â”€ migrations/         # SQL migration files
â”‚   â”œâ”€â”€ seeds/              # Initial data
â”‚   â””â”€â”€ initdb/             # Initialization scripts
â”œâ”€â”€ scripts/                # Utility and management scripts
â”‚   â”œâ”€â”€ test_*.py          # Test and validation scripts
â”‚   â”œâ”€â”€ quick_setup.py     # Quick configuration utility
â”‚   â””â”€â”€ health_check.py    # System health monitoring
â”œâ”€â”€ docs/                   # Documentation and guides
â”œâ”€â”€ tests/                  # Test suites and fixtures
â”œâ”€â”€ service_documents/      # Sample documents for testing
â”œâ”€â”€ docker-compose.simple.yml      # Minimal development setup
â”œâ”€â”€ docker-compose.with-firecrawl.yml  # Development with Firecrawl
â”œâ”€â”€ docker-compose.production.yml   # Production deployment
â”œâ”€â”€ .env.example           # Environment template
â””â”€â”€ README.md              # This file
```

## ðŸ§ª Testing Your Setup

### Quick Validation

```bash
# Test all services
python scripts/quick_test.py

# Expected output:
# âœ… Database: Connected
# âœ… Storage: Connected  
# âœ… AI Service: Connected
```

### Document Processing Test

```bash
# Process a sample document
python scripts/test_single_document.py service_documents/sample.pdf

# Expected output:
# Processing: sample.pdf (2.3MB)
# Upload completed
# Text processing: 45 chunks generated
# Hierarchical structure: 12 sections detected
# SVG extraction: 3 vector graphics found
# Table extraction: 2 tables processed
# Context extraction: 8 media items analyzed
# Embeddings generated: 55 total embeddings
# Document processed successfully!
```

### Search Functionality Test

```bash
# Test multimodal search
python scripts/test_search.py --query "fuser unit error"

# Expected output:
# ðŸ” Searching: "fuser unit error"
# ðŸ“Š Results found: 12
# ðŸ“„ Text chunks: 8
# ðŸ–¼ï¸ Images: 2  
# ðŸ“Š Tables: 1
# ðŸŽ¥ Videos: 1
# â±ï¸ Search time: 45ms
# ðŸŽ‰ Search completed successfully!
```

## ðŸ” Common Issues & Solutions

### Port Conflicts

**Problem**: Services fail to start due to port conflicts

**Solution**: Change ports in `.env`:
```bash
# Change API port
API_PORT=8001

# Change frontend port  
FRONTEND_PORT=3001

# Change database port
POSTGRES_PORT=5433
```

### Memory Issues

**Problem**: System runs out of memory during processing

**Solution**: Reduce resource usage:
```bash
# Lower batch sizes
EMBEDDING_BATCH_SIZE=5
MAX_CONCURRENT_PROCESSES=1

# Use smaller test documents
MAX_FILE_SIZE_MB=10
```

### Permission Issues

**Problem**: File permission errors on document uploads

**Solution**: Fix permissions:
```bash
# Set proper permissions
sudo chown -R $USER:$USER service_documents/
chmod -R 755 service_documents/

# Or use Docker volumes for storage
docker-compose down -v
docker-compose up -d
```

### Firecrawl Connection Issues

**Problem**: Cannot connect to Firecrawl API

**Solution**: Check Firecrawl services:
```bash
# Check if Firecrawl services are running
docker-compose ps | grep firecrawl

# Restart Firecrawl services
docker-compose restart krai-firecrawl-api krai-firecrawl-worker

# Check Firecrawl logs
docker-compose logs krai-firecrawl-api

# Verify health endpoint
curl http://localhost:3002/health

# If still failing, use BeautifulSoup fallback
SCRAPING_BACKEND=beautifulsoup
```

### Database Connection Issues

**Problem**: Cannot connect to PostgreSQL

**Solution**: Check database status:
```bash
# Check if database is running
docker-compose ps postgresql

# Restart database service
docker-compose restart postgresql

# Check database logs
docker-compose logs postgresql
```

## ðŸ“š Next Steps

### 1. Add Your Documents

```bash
# Place documents in service directory
cp your_documents/*.pdf service_documents/

# Process documents
python scripts/process_documents.py service_documents/
```

### 2. Explore the API

```bash
# View API documentation
open http://localhost:8000/docs

# Test API endpoints
curl http://localhost:8000/api/health
curl http://localhost:8000/api/documents
curl http://localhost:8000/api/search?q=test

# Test Firecrawl scraping (if enabled)
curl http://localhost:8000/api/scraping/health
```

### 3. Use the Web Interface

```bash
# Open dashboard
open http://localhost:3000

# Features available:
# - Document upload and management
# - Processing status monitoring
# - Search interface
# - Results visualization
```

### 4. Run Comprehensive Tests

```bash
# Full test suite
python scripts/test_full_pipeline_phases_1_6.py

# Integration tests
pytest tests/integration/ -v

# Performance tests
python scripts/test_multimodal_search.py --performance
```

## ðŸ› ï¸ Advanced Configuration

### Custom AI Models

```bash
# Use different Ollama models
OLLAMA_MODEL=mistral
OLLAMA_MODEL=codellama

# Configure OpenAI
OPENAI_API_KEY=sk-your-key
OPENAI_MODEL=gpt-4

# Use local embedding models
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
```

### Database Optimization

```bash
# Enable vector indexes
ENABLE_VECTOR_INDEX=true
VECTOR_INDEX_TYPE=ivfflat

# Configure connection pooling
DATABASE_POOL_SIZE=50
MAX_CONNECTIONS=100

# Enable query caching
ENABLE_QUERY_CACHE=true
CACHE_TTL=3600
```

### Storage Configuration

```bash
# Use external S3 instead of MinIO
STORAGE_TYPE=s3
AWS_ACCESS_KEY_ID=your-key
AWS_SECRET_ACCESS_KEY=your-secret
AWS_BUCKET_NAME=krai-documents
AWS_REGION=us-west-2

# Configure storage lifecycle
STORAGE_RETENTION_DAYS=365
AUTO_CLEANUP_TEMP_FILES=true
```

## ðŸ“– Additional Resources

### Documentation
- [ðŸ“– Full Documentation](docs/README.md)
- [ðŸ”§ Installation Guide](docs/setup/INSTALLATION_GUIDE.md)
- [ðŸ§ª Testing Guide](docs/TESTING_GUIDE_PHASES_1_6.md)
- [ðŸ—ï¸ Architecture Overview](docs/architecture/KRAI_PROCESSING_ARCHITECTURE_PLAN.md)
- [ðŸŒ Web Scraping Guide](docs/PRODUCT_RESEARCH.md)
- [ðŸ“ Firecrawl Examples](examples/README.md)

### API Reference
- [ðŸ“š API Documentation](http://localhost:8000/docs)
- [ðŸ” Search API Guide](docs/api/SEARCH_API.md)
- [ðŸ“¤ Upload API Guide](docs/api/CONTENT_API.md)
- [ðŸ” Authentication Guide](docs/api/AUTHENTICATION.md)

### Development
- [ðŸ› Bug Reports](https://github.com/your-org/KRAI-minimal/issues)
- [ðŸ’¡ Feature Requests](https://github.com/your-org/KRAI-minimal/discussions)
- [ðŸ¤ Contributing Guide](CONTRIBUTING.md)
- [ðŸ“‹ Project Roadmap](docs/ROADMAP.md)

### Community
- [ðŸ’¬ Discord Community](https://discord.gg/krai)
- [ðŸ“§ Mailing List](https://groups.google.com/g/krai-users)
- [ðŸ¦ Twitter Updates](https://twitter.com/krai_project)
- [ðŸ“º YouTube Tutorials](https://youtube.com/c/krai-tutorials)

## ðŸŽ¯ Need Help?

If you encounter any issues during setup:

1. **Check the logs**: `docker-compose logs [service-name]`
2. **Run health check**: `python scripts/health_check.py`
3. **Review troubleshooting**: [Troubleshooting Guide](docs/TROUBLESHOOTING.md)
4. **Ask the community**: [GitHub Discussions](https://github.com/your-org/KRAI-minimal/discussions)
5. **Report issues**: [GitHub Issues](https://github.com/your-org/KRAI-minimal/issues)

---

**ðŸŽ‰ Congratulations!** You now have a fully functional KRAI system with all Phase 1-6 features ready for document processing, multimodal search, and intelligent content analysis.

**Next**: Check out the [Testing Guide](docs/TESTING_GUIDE_PHASES_1_6.md) to validate your setup and explore advanced features.
