# OpenWebUI Integration f√ºr KRAI

## üéØ √úbersicht

KRAI bietet jetzt eine **OpenAI-kompatible API**, die direkt mit OpenWebUI verwendet werden kann!

## ‚úÖ Was ist implementiert?

### OpenAI-Compatible Endpoints
- ‚úÖ `GET /v1/models` - Liste verf√ºgbarer Modelle
- ‚úÖ `POST /v1/chat/completions` - Chat-Completions (streaming & non-streaming)

### Features
- ‚úÖ **Fehlercode-Suche** - Automatische Erkennung von Fehlercodes (C9402, 10.00.33, etc.)
- ‚úÖ **Semantic Search** - Vector-basierte Suche f√ºr allgemeine Fragen
- ‚úÖ **Streaming Support** - Echtzeitantworten im Chat
- ‚úÖ **Multi-Hersteller** - HP, Konica Minolta, Canon, etc.

## üöÄ Setup

### 1. API l√§uft bereits

Die API l√§uft auf: `http://localhost:8000`

Teste die OpenAI-kompatiblen Endpoints:

```powershell
# Modelle auflisten
curl http://localhost:8000/v1/models

# Chat Completion (non-streaming)
curl -X POST http://localhost:8000/v1/chat/completions `
  -H "Content-Type: application/json" `
  -d '{
    "model": "krai-assistant",
    "messages": [
      {"role": "user", "content": "Konica Minolta C3320i Fehler C9402"}
    ]
  }'
```

### 2. OpenWebUI Installation

#### Option A: Docker (Empfohlen)

```powershell
# OpenWebUI mit Docker starten
docker run -d `
  -p 3000:8080 `
  --name openwebui `
  -e OPENAI_API_BASE_URLS=http://host.docker.internal:8000/v1 `
  -e OPENAI_API_KEYS=dummy-key `
  ghcr.io/open-webui/open-webui:main
```

**Wichtig f√ºr Windows:**
- `host.docker.internal` erm√∂glicht Docker-Container Zugriff auf localhost
- Port 3000 f√ºr OpenWebUI (um Konflikt mit Port 8000 zu vermeiden)

#### Option B: Lokale Installation

```powershell
# Python Virtual Environment
python -m venv openwebui-env
.\openwebui-env\Scripts\activate

# OpenWebUI installieren
pip install open-webui

# Starten
open-webui serve --port 3000
```

### 3. OpenWebUI Konfiguration

1. **√ñffne OpenWebUI**: `http://localhost:3000`

2. **Erstelle einen Account** (erster User wird Admin)

3. **Gehe zu Settings** ‚Üí **Connections**

4. **OpenAI API konfigurieren**:
   - **API Base URL**: `http://localhost:8000/v1` (oder `http://host.docker.internal:8000/v1` bei Docker)
   - **API Key**: `dummy-key` (wird nicht validiert)
   - Klicke **Save**

5. **Modell ausw√§hlen**:
   - Gehe zu **Models**
   - W√§hle `krai-assistant`
   - Starte einen Chat!

## üß™ Test-Queries

Probiere diese Queries in OpenWebUI:

### Fehlercode-Suche
```
Konica Minolta C3320i Fehler C9402
```

```
HP Fehler 10.00.33
```

### Allgemeine Fragen
```
Wie behebe ich einen Papierstau?
```

```
Toner wechseln Anleitung
```

## üìä Erwartete Antworten

### Fehlercode C9402
```
**Fehlercode C9402** (Konica Minolta):
- **Beschreibung**: Exposure LED lighting abnormally...
- **L√∂sung**: 1. Turn OFF the machine. 2. Check the connection...
- **Seite**: 450
```

### Semantic Search
```
**Relevante Informationen:**
1. Paper Registration shutter Paper Tray 2 media type detection... (Relevanz: 0.55)
2. ...
```

## üîß Troubleshooting

### OpenWebUI kann API nicht erreichen

**Problem**: Connection refused oder timeout

**L√∂sung**:
```powershell
# Pr√ºfe ob KRAI API l√§uft
curl http://localhost:8000/health

# Pr√ºfe OpenAI-Endpoint
curl http://localhost:8000/v1/models
```

### Docker kann localhost nicht erreichen

**Problem**: Docker-Container kann nicht auf localhost:8000 zugreifen

**L√∂sung**: Verwende `host.docker.internal` statt `localhost`:
```
http://host.docker.internal:8000/v1
```

### Keine Antworten

**Problem**: OpenWebUI zeigt keine Antworten

**L√∂sung**:
1. Pr√ºfe API-Logs im Terminal wo `python main.py` l√§uft
2. Pr√ºfe Browser-Console (F12) in OpenWebUI
3. Teste direkt mit curl (siehe oben)

### Streaming funktioniert nicht

**Problem**: Antworten kommen nicht in Echtzeit

**L√∂sung**: 
- Streaming ist implementiert, aber OpenWebUI zeigt manchmal erst am Ende
- Das ist normal und ein OpenWebUI-Verhalten

## üé® OpenWebUI Features

### Was funktioniert:
- ‚úÖ Chat-Interface
- ‚úÖ Conversation History
- ‚úÖ Model Selection
- ‚úÖ Streaming Responses
- ‚úÖ Markdown Formatting

### Was NICHT funktioniert:
- ‚ùå Function Calling (noch nicht implementiert)
- ‚ùå Image Upload (Vision Model separat)
- ‚ùå Voice Input/Output

## üìà N√§chste Schritte

### Sofort verf√ºgbar:
1. ‚úÖ Starte OpenWebUI
2. ‚úÖ Teste Fehlercode-Suche
3. ‚úÖ Teste Semantic Search

### Zuk√ºnftige Erweiterungen:
- [ ] Function Calling Support
- [ ] RAG mit Conversation Context
- [ ] Multi-Turn Conversations mit Memory
- [ ] Image Upload f√ºr Defect Detection
- [ ] Voice Input/Output

## üîê Sicherheit

**Wichtig f√ºr Produktion:**

1. **API Key Validation**: Aktuell wird kein API Key validiert
2. **CORS**: Aktuell erlaubt f√ºr alle Origins (`*`)
3. **Rate Limiting**: Nicht implementiert

F√ºr Produktion solltest du:
```python
# In openai_compatible_api.py
from fastapi import Header, HTTPException

async def verify_api_key(authorization: str = Header(None)):
    if not authorization or authorization != f"Bearer {EXPECTED_API_KEY}":
        raise HTTPException(status_code=401, detail="Invalid API key")
```

## üìû Support

Bei Problemen:
1. Pr√ºfe API-Logs
2. Pr√ºfe OpenWebUI-Logs: `docker logs openwebui`
3. Teste Endpoints direkt mit curl

## üéâ Fertig!

Du hast jetzt ein vollst√§ndiges Chat-Interface f√ºr KRAI! üöÄ

**Viel Spa√ü beim Testen!**
