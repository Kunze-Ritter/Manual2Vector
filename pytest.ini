[pytest]
# Pytest configuration for KRAI project

# Custom markers registration
markers =
    unit: Unit tests (fast, isolated)
    integration: Integration tests (require external services)
    e2e: End-to-end tests (full workflow)
    firecrawl: Tests requiring Firecrawl service
    fallback: Tests for fallback behavior
    llm: Tests for LLM provider functionality
    slow: Tests that take longer to run
    # Processor-specific markers
    processor: Tests for pipeline processors (Upload, Document, Text, structured processors)
    upload: Tests for UploadProcessor functionality
    document: Tests for DocumentProcessor functionality
    text: Tests for TextProcessor/TextExtractor functionality
    pipeline: Tests for complete pipeline flow
    chunking: Tests for SmartChunker functionality
    stage_tracker: Tests for StageTracker integration
    smoke: Quick smoke tests to verify basic functionality
    table: Tests for TableProcessor
    svg: Tests for SVGProcessor
    image: Tests for ImageProcessor
    visual_embedding: Tests for VisualEmbeddingProcessor
    multimodal: Tests for multi-modal content handling
    link: Tests for LinkExtractionProcessorAI and link extractor functionality
    chunk_prep: Tests for ChunkPreprocessor functionality
    classification: Tests for ClassificationProcessor and document type detection
    link_enrichment: Tests for LinkEnrichmentService integration
    metadata: Tests for MetadataProcessor and metadata extraction
    parts: Tests for PartsProcessor and parts extraction
    series: Tests for SeriesProcessor and series detection
    storage: Tests for StorageProcessor and artifact persistence
    error_codes: Tests for error code extraction
    versions: Tests for version and edition extraction
    storage: Tests for object storage integration
    embedding: Tests for EmbeddingProcessor functionality
    search: Tests for SearchProcessor and search indexing
    embedding_quality: Tests for embedding quality validation
    search_quality: Tests for search relevance and quality
    master_pipeline: Tests for KRMasterPipeline orchestration and helpers
    batch: Tests for batch document processing and hardware waker
    concurrency: Tests for concurrency limits and parallel execution
    error_recovery: Tests for pipeline error handling and recovery
    status_tracking: Tests for pipeline stage/status tracking
    proxy: Tests for proxy configuration and authentication
    timeout: Tests for timeout handling
    retry: Tests for retry mechanisms
    health_check: Tests for health check functionality
    backend_switching: Tests for backend switching
    performance: Performance and benchmark tests
    verification: Verification tests for pipeline stages
    dependencies: Tests for stage dependency enforcement
    ollama: Tests requiring Ollama service
    # Database adapter markers
    postgresql: Tests that require PostgreSQL database
    adapter: Tests for DatabaseAdapter interface
    mock_db: Tests using MockDatabaseAdapter

# Test discovery
testpaths = 
    backend/tests
    tests/processors
    tests/verification

# Output options
addopts = 
    -v
    --tb=short
    --strict-markers
    --disable-warnings
    --ignore=tests/processors/test_embedding_processor.py

# Async test configuration
asyncio_mode = auto

# Timeout for tests (in seconds) - increased for processor tests
timeout = 600

# Minimum Python version
minversion = 6.0

# Logging configuration
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Coverage configuration (when used with --cov)
# addopts = --cov=backend --cov-report=html --cov-report=term-missing --cov-fail-under=80
# addopts = --cov=backend/processors --cov-report=html --cov-report=term-missing --cov-fail-under=80

# Processor-specific options
# addopts = --pdf-path=/path/to/test/pdfs --skip-slow-tests

# Filter for processor tests
# addopts = -m processor

